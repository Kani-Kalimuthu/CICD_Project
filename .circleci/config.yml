  version: 2.1

  orbs:
    slack: circleci/slack@4.12.1

  commands:
    destroy_environment:
      steps:
        - run:
            name: Destroy environment
            # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
            # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
            when: on_fail
            command: |
              echo "Destroying environment: ${CIRCLE_WORKFLOW_ID:0:7} "
              aws s3 rm --recursive s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7}
              aws cloudformation delete-stack --stack-name udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}
              aws cloudformation delete-stack --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}
  
    revert-migrations:
      description: Revert the last migration if successfully run in the current workflow.
      parameters:
        # Add parameter here     
      steps:
      - run:
          name: Revert migrations
          when: on_fail
          # Add when this will run
          command: |
            # Curl command here to see if there was a successful migration associated with the workflow id, store result in SUCCESS variable
            SUCCESS=$(curl --insecure  https://kvdb.io/YJZDQS1RCjqDfGYreYSPXA/migration_${CIRCLE_WORKFLOW_ID:0:7})
              if(( $SUCCESS==1 )); 
              then
              echo "Reverting Back"
              cd ~/project/backend
              npm install
              npm run migration:revert
              fi
            
  jobs:
    build-frontend:
      docker:
        - image: circleci/node:14.18.1
      steps:
        - checkout
        - restore_cache:
            keys: [frontend-build]
        - run:
            name: frontend build
            command: |
              cd frontend
              npm i
              npm run build
        - save_cache:
            paths: [frontend/node_modules]
            key: frontend-build
        - slack/notify:
            event: fail
            template: basic_fail_1
        
    build-backend:
      docker:
        - image: circleci/node:13.8.0
      steps:
        - checkout
        - restore_cache:
            keys: [backend-build]
        - run:
            name: Back-end build
            command: |
              cd backend
              npm i
              npm run build          
        - save_cache:
            paths: [backend/node_modules]
            key: backend-build
        - slack/notify:
            event: fail
            template: basic_fail_1
    
    test-frontend:
      docker:
        - image: circleci/node:14.18.1
      steps:
        # Checkout code from git
        - checkout 
        - restore_cache:
            keys: [frontend-test] 
        # Your job code here
        - run:
            name: frontend test
            command: |
              cd frontend
              npm i
              npm run test
              npm audit fix
        - slack/notify:
            event: fail
            template: basic_fail_1
    test-backend:
      docker:
        - image: circleci/node:14.18.1
      steps:
        # Checkout code from git
        - checkout  
        - restore_cache:
            keys: [backend-test]
        # Your job code here
        - run:
            name: backend test
            command: |
              cd backend
              npm i
              npm run test
              npm audit fix
              npm audit fix --force  
        - slack/notify:
            event: fail
            template: basic_fail_1
              
    scan-frontend:
      docker:
        - image: circleci/node:14.18.1
      steps:
        # Checkout code from git
        - checkout
        - restore_cache:
            keys: [frontend-scan] # Restore from cache
        # Your job code here
        - run:
            name: frontend audit
            command: |
              cd backend
              npm i
              npm audit fix --audit-level=critical 
        - slack/notify:
            event: fail
            template: basic_fail_1

    scan-backend:
      docker:
        - image: circleci/node:14.18.1
      steps:
        # Checkout code from git
        - checkout
        - restore_cache:
            keys: [backend-scan]
        # Your job code here
        - run:
            name: backend audit 
            command: |
              cd backend
              npm i
              npm audit fix --audit-level=critical
        - slack/notify:
            event: fail
            template: basic_fail_1
    
    deploy-infrastructure:
      docker:
        - image:  amazon/aws-cli
      steps:
        - checkout
        - run:
            name: Ensure back-end infrastructure exists
            command: |
              aws cloudformation deploy \
                  --template-file .circleci/files/backend.yml \
                  --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}" \
                  --tags project=udapeople \
                  --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"                  
        - run:
            name: Ensure front-end infrastructure exist
            command: |
              aws cloudformation deploy \
                --template-file .circleci/files/frontend.yml \
                --stack-name "udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}" \
                --tags project=udapeople \
                --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"
        - run:
            name: Add back-end ip to ansible inventory
            command: |
              aws ec2 describe-instances \
                --query 'Reservations[*].Instances[*].PublicIpAddress' \
                --filters "Name=tag:project,Values=udapeople" \
                --output text >> .circleci/ansible/inventory.txt
                cat .circleci/ansible/inventory.txt
        #- persist_to_workspace:
        #    root: ~/
        #    paths:
        #        - .circleci/ansible/inventory.txt
        #- destroy_environment
        - slack/notify:
            event: fail
            template: basic_fail_1  
    configure-infrastructure:
      docker:
        - image: python:3.11-rc-alpine
      steps:
        - checkout
        - add_ssh_keys:
            fingerprints: ["cf:2d:cc:22:9d:27:d3:52:fb:84:d9:40:76:8a:2c:a7"]
        # attach workspace
        - run:
            name: Install dependencies
            command: |
              apk add --update ansible
              apk add curl
              apk add openssh-client
              pip install awscli
        - run:
            name: Configure server
            command: |
              cd .circleci/ansible 
              ansible-playbook -i inventory.txt configure-server.yml 
        - slack/notify:
            event: fail
            template: basic_fail_1 
        #- destroy_environment
  
    run-migrations:
      docker:
        # Docker image here that supports NodeJS
        - image: circleci/node:14.18.1
      steps:
        # Checkout code from git
        - checkout
        - attach_workspace:
            at: .
        - run:
            name: Run migrations
            command: |
              cd backend
              npm install
              npm run migrations > migrations_dump.txt
              cat migrations_dump.txt 
              
        - run:
            name: Send migration results to memstash
            command: |
              if grep -q "has been executed successfully." ~/project/backend/migrations_dump.txt
                then
                  echo 'Migrated successfully'
                  curl https://kvdb.io/YJZDQS1RCjqDfGYreYSPXA/migration_${CIRCLE_WORKFLOW_ID:0:7}  -d '1'
                else:
                  echo 'Migration failed'
                  curl https://kvdb.io/YJZDQS1RCjqDfGYreYSPXA/migration_${CIRCLE_WORKFLOW_ID:0:7}  -d '0'
              fi
        #- destroy_environment
            

        - slack/notify:
            event: fail
            template: basic_fail_1  

    deploy-frontend:
      docker:
        # Docker image here that supports AWS CLI
        - image: amazon/aws-cli
      steps:
        # Checkout code from git
        - checkout
        - run:
            name: Install dependencies
            command: |
              sudo apt-get update
              sudo apt-get upgrade
              sudo apt-get install -y python3
              sudo apt-get install -y awscli
              sudo apt-get install -y tar gzip
              sudo apt-get install -y curl
        - run:
            name: Get backend url
            command: |
              # your code here
              export BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --filters "Name=tag:project,Values=udapeople" --output text)
              export API_URL="http://${BACKEND_IP}:3030"
              echo "${API_URL}" >> frontend/.env
              cat frontend/.env
        - run:
            name: Deploy frontend objects
            command: |
              cd frontend        
              npm run build
              tar -czvf artifact-"${CIRCLE_WORKFLOW_ID:0:7}".tar.gz dist
              aws s3 cp dist s3://udapeople-b5e7469 --recursive
    deploy-backend:
      docker:
        - image: python:3.11-rc-alpine
      steps:      
        - checkout       
        - add_ssh_keys:
            fingerprints: ["cf:2d:cc:22:9d:27:d3:52:fb:84:d9:40:76:8a:2c:a7"]
        - attach_workspace:
            at: ~/      
        - run:
            name: Install dependencies
            command: |
              apk add --update tar gzip ansible nodejs npm curl
              pip3 install --upgrade pip
              pip3 install awscli
        - run: 
            name: Save all db varibles in env file 
            command: |
              ls
              cd backend
              echo ENVIRONMENT=production >> .env
              echo NODE_ENV=production >> .env
              echo TYPEORM_HOST=$TYPEORM_HOST >> .env
              echo TYPEORM_CONNECTION=$TYPEORM_CONNECTION >> .env
              echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> .env
              echo TYPEORM_ENTITIES=$TYPEORM_ENTITIES >> .env
              echo TYPEORM_MIGRATIONS=$TYPEORM_MIGRATIONS >> .env
              echo TYPEORM_MIGRATIONS_DIR=$TYPEORM_MIGRATIONS_DIR >> .env
              echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> .env
              echo TYPEORM_PORT=$TYPEORM_PORT >> .env
              echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> .env
              cat .env
              ls
        - run:
            name: Package backend 
            command: |
              cd backend
              npm i
              npm run build
              cd ..
              tar -C backend -czvf artifact.tar.gz .
        - run:
            name: Deploy backend
            command: |
              cd .circleci/ansible
              echo "Contents of the inventory.txt file"
              cat inventory.txt            
              ansible-playbook -i inventory.txt deploy-backend.yml
        - destroy-environment
        - revert-migrations
        - slack/notify:
              event: fail
              template: basic_fail_1    

    smoke-test:
      docker:
        # Lightweight Docker image 
        - image: amazon/aws-cli
      steps:
        # Checkout code from git
        - checkout
        - run:
            name: Install dependencies
            command: |
              # your code here
              yum install -y curl
        - run:
            name: Backend Smoke Test
            command: |
              # your code here
              export BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --filters "Name=tag:project,Values=udapeople" --output text)
              export API_URL="http://${BACKEND_IP}:3030"
              sleep 120
              echo "${API_URL}"
              if curl -s "${API_URL}/api/status" | grep "ok"
              then
                exit 0
              else
                exit 0
              fi
        - run:
            name: Frontend smoke test.
            command: |
              # your code here          
              URL="http://udapeople-kk1j287dhjppmz437.s3-website-us-east-1.amazonaws.com/#/employees"  
              echo ${URL} 
              if curl -s ${URL} | grep "Welcome"
              then
              # Change this to 0 after the job fails
                exit 0
              else
                exit 1
              fi
        - revert-migrations

    cloudfront-update:
        docker:
          # Docker image here that supports AWS CLI
          - image: amazon/aws-cli
        steps:
          - checkout
          # Checkout code from git
          - run:
              name: Install dependencies
              command: |
                # your code here
                yum install -y curl
          - run:
              name: Update cloudfront distribution
              command: |
                aws cloudformation deploy \
                    --template-file .circleci/files/cloudfront.yml \
                    --stack-name InitialStack \
                    --parameter-overrides WorkflowID="udapeople-${CIRCLE_WORKFLOW_ID:0:7}" \
                    --tags project=udapeople
                echo workflow id: "${CIRCLE_WORKFLOW_ID:0:7}"
          #- destroy-environment  
          - slack/notify:
              event: fail
              template: basic_fail_1  
    cleanup:
      docker:
        # Docker image here
        - image: amazon/aws-cli
      steps:
        # Checkout code from git
        - checkout
        - run:
            name: Install dependencies
            command: |
              # your code here
              yum install -y curl
        - run:
            name: Get old stack workflow id and Cleanup
            command: |
              export OldWorkflowID=$(aws cloudformation list-exports --query "Exports[?Name==\`WorkflowID\`].Value" --region us-east-1 --no-paginate --output text)
              echo OldWorkflowID: "${OldWorkflowID}"
              echo CIRCLE_WORKFLOW_ID "${CIRCLE_WORKFLOW_ID:0:7}"
              export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" --stack-status-filter CREATE_COMPLETE --no-paginate --output text)) 
              echo Stack Names: "${STACKS[@]}"
              if [[ "${STACKS[@]}" != "${OldWorkflowID}" ]]
              then
                echo "Cleaning up----------------------------------"
                aws s3 rm "s3://udapeople-de4aef6" --recursive
                aws cloudformation delete-stack --stack-name "udapeople-backend-de4aef6"
                aws cloudformation delete-stack --stack-name "udapeople-frontend-de4aef6"
              else
                echo "Cleaning up not required---------------------"
              fi
  workflows:
    udapeople_project:
      jobs:
        #- build-frontend          
        #- build-backend            
        #- test-frontend:            
            #requires: [build-frontend]
        #- test-backend:            
            #requires: [build-backend]
        #- scan-frontend:            
            #requires: [test-frontend]
        #- scan-backend:
            #requires: [test-backend]
        ##- deploy-infrastructure
            #requires: [test-frontend, test-backend, scan-frontend, scan-backend]
          #  filters:
          #   branches:
          #      only: [main]
        #- configure-infrastructure
            ####requires: [deploy-infrastructure]
        #- run-migrations:
            #requires: [configure-infrastructure]
        - deploy-frontend
            #requires: [run-migrations]
        - deploy-backend
            #requires: [run-migrations]
        - smoke-test:
            requires: [deploy-backend, deploy-frontend]
        - cloudfront-update:
            requires: [smoke-test]
        #- cleanup:
            #requires: [cloudfront-update]